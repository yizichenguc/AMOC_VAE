{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a37fe55-82d9-48a8-ad38-2832b4889e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcad3a7-761a-40b0-bccd-f1809d988697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe99622-842b-4d2a-b3d4-c6316c12ace8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "AMOC_Obs = pd.read_csv('input_data/dtdata_AMOC_Obs.csv', index_col = 0) # 1680 rows × 2 columns\n",
    "AMOC_Ensemble = pd.read_csv('input_data/dtdata_AMOC_Ensemble.csv', index_col = 0) # 5988 rows × 29 columns\n",
    "\n",
    "AMOCindex_Obs = pd.read_csv('input_data/dtdata_AMOCindex_Obs.csv', index_col = 0) # 1680 rows × 2 columns\n",
    "AMOCindex_Ensemble = pd.read_csv('input_data/dtdata_AMOCindex_Ensemble.csv', index_col = 0) # 5988 rows × 29 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df0491c-9817-4b07-b9c9-ba62d1669326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to min-max scale the input data according to universe data, prevent certain dimension domian.\n",
    "# Input should be a list of pandas dataframe, will be combined column-wise.\n",
    "class Scaler:\n",
    "    def __init__(self, data):\n",
    "        data = pd.concat(data, axis = 1)\n",
    "\n",
    "        self.min = data.min().min()\n",
    "        self.max = data.max().max()\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.min) / (self.max - self.min)\n",
    "    \n",
    "    # Transform data back to de-meaned version of original data: for further pre-processing, all data are de-meaned with pseudo-non-missing part of data. This function transform data back to\n",
    "    # de-meaned version of original data. To transform back the long-term trend (output of model) should use this function too.\n",
    "    def inverse_transform(self, X):\n",
    "        return X * (self.max - self.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "900dd89d-dee7-4c86-bd88-6a4fb3a5db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled data for AMOC\n",
    "\n",
    "AMOC_scaler = Scaler([AMOC_Obs[['Obs']], AMOC_Ensemble[[str(i) for i in range(1, 29)]]])\n",
    "# copy(): The copy() method creates a shallow copy of a DataFrame. This means that the new object points \n",
    "# to the same data as the original object. Any changes made to the copy will affect the original object.\n",
    "# The copy(deep = True) method creates a deep copy of a DataFrame. This means that the new object has its own \n",
    "# copy of the data. Changes made to the copy will not affect the original object.\n",
    "AMOC_Obs_std = AMOC_Obs.copy(deep = True)\n",
    "AMOC_Ensemble_std = AMOC_Ensemble.copy(deep = True)\n",
    "\n",
    "AMOC_Obs_std[['Obs']] = AMOC_scaler.transform(AMOC_Obs_std[['Obs']])\n",
    "AMOC_Ensemble_std[[str(i) for i in range(1, 29)]] = AMOC_scaler.transform(AMOC_Ensemble_std[[str(i) for i in range(1, 29)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30c50f91-8492-444b-b068-ae2df0f3de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled data for AMOC index\n",
    "\n",
    "AMOCindex_scaler = Scaler([AMOCindex_Obs[['Obs']], AMOCindex_Ensemble[[str(i) for i in range(1, 29)]]])\n",
    "\n",
    "AMOCindex_Obs_std = AMOCindex_Obs.copy(deep = True)\n",
    "AMOCindex_Ensemble_std = AMOCindex_Ensemble.copy(deep = True)\n",
    "\n",
    "AMOCindex_Obs_std[['Obs']] = AMOCindex_scaler.transform(AMOCindex_Obs_std[['Obs']])\n",
    "AMOCindex_Ensemble_std[[str(i) for i in range(1, 29)]] = AMOCindex_scaler.transform(AMOCindex_Ensemble_std[[str(i) for i in range(1, 29)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a380c067-942f-479d-bae2-9c96bd12945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check scaling by plotting\n",
    "# i = 0\n",
    "# a = AMOC_Ensemble.iloc[i:(i+1680),9]\n",
    "# a_std = AMOC_Ensemble_std.iloc[i:(i+1680),9]\n",
    "\n",
    "# plt.plot(a)\n",
    "# # plt.plot(a_std)\n",
    "# # plt.plot(a_std * (AMOC_scaler.max - AMOC_scaler.min) + AMOC_scaler.min)\n",
    "# plt.plot(AMOC_scaler.inverse_transform(a_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab8fc22f-c007-4e83-9d38-a686d86a0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set seed\n",
    "\n",
    "# tf.random.set_seed(seed)\n",
    "# os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8364946-ec80-40e3-bf82-32cfe55ce570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input data to use in DVAE\n",
    "\n",
    "# Randomly sample 6,000 different time segments from 499 years (5,988 data points) Ensemble data; for each time segment,\n",
    "# there will be 28 different training examples. Total would be 6,000 * 28 = 168,000 data set.\n",
    "num_select = 6000\n",
    "\n",
    "AMOC = np.array(AMOC_Ensemble_std[[str(i) for i in range(1, 29)]])\n",
    "AMOC_index = np.array(AMOCindex_Ensemble_std[[str(i) for i in range(1, 29)]])\n",
    "\n",
    "Ensemble_length = AMOC.shape[0] # 5,988 (499 years)\n",
    "Obs_length = len(AMOC_Obs_std) # 1,680 (140 years)\n",
    "mask = np.array(~AMOC_Obs_std['Obs'].isna()) # non-missing part in observation data\n",
    "\n",
    "# start_list: List of start index of length 1,680 time segments from Ensemble data.\n",
    "np.random.seed(seed)\n",
    "start_list = [np.random.randint(0, Ensemble_length - Obs_length) for i in range(num_select)]\n",
    "\n",
    "# AMOC_input: AMOC data corresponding to observation non-miss part.\n",
    "# AMOCindex_input: AMOC Index data with same time segment corresponding to AMOC\n",
    "# target: AMOC long term trend, generated from 2-degree polynomial fitting of 28 Ensemble trails to filter out nature variability.\n",
    "AMOC_input = []\n",
    "AMOCindex_input = []\n",
    "target = []\n",
    "\n",
    "for start in start_list:\n",
    "    AMOC_seg = AMOC[start:(start + Obs_length), :] # 1,680 * 28\n",
    "    AMOC_seg_masked = AMOC_seg[mask, :] # 179 * 28\n",
    "    \n",
    "    # De-mean AMOC data with mean of non-missing part data, which corresponding to real-world data: only non-missing part is known.\n",
    "    mean = AMOC_seg_masked.mean(axis = 0)\n",
    "    AMOC_seg = AMOC_seg - mean\n",
    "    AMOC_seg_masked = AMOC_seg_masked - mean\n",
    "    \n",
    "    # Fit 2-degree polynomial with 28 ensemble trails\n",
    "    x = np.array(range(Obs_length))\n",
    "    # ploy: Polynomial coefficients, highest power first.\n",
    "    poly = np.polyfit(x.repeat(AMOC_seg.shape[1]), AMOC_seg.flatten(), 2)\n",
    "    y = x**2 * poly[0] + x * poly[1] + poly[2]\n",
    "    y = np.reshape(y, (y.shape[0], 1)) # 1,680 * 1\n",
    "    y = y.repeat(AMOC_seg.shape[1], axis = 1) # 1,680 * 28\n",
    "\n",
    "    # De-mean AMOC index data.\n",
    "    AMOCindex_seg = AMOC_index[start:(start + Obs_length), :]\n",
    "    mean = AMOCindex_seg.mean(axis = 0)\n",
    "    AMOCindex_seg = AMOCindex_seg - mean\n",
    "    \n",
    "    # Reshape data to (number of trails, number of timesteps, dimension)\n",
    "    AMOC_seg_masked = np.reshape(np.ravel(AMOC_seg_masked, order = 'F'), (AMOC_seg_masked.shape[1], AMOC_seg_masked.shape[0], 1))\n",
    "    AMOCindex_seg = np.reshape(np.ravel(AMOCindex_seg, order = 'F'), (AMOCindex_seg.shape[1], AMOCindex_seg.shape[0], 1))\n",
    "    y = np.reshape(np.ravel(y, order = 'F'), (y.shape[1], y.shape[0], 1))\n",
    "    \n",
    "    AMOC_input.append(AMOC_seg_masked)\n",
    "    AMOCindex_input.append(AMOCindex_seg)\n",
    "    target.append(y)\n",
    "    \n",
    "AMOC_input = np.vstack(AMOC_input)\n",
    "AMOCindex_input = np.vstack(AMOCindex_input)\n",
    "target = np.vstack(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "337329b1-84be-4cbf-ae0c-b28de59b8dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168000, 179, 1)\n",
      "(168000, 1680, 1)\n",
      "(168000, 1680, 1)\n"
     ]
    }
   ],
   "source": [
    "print(AMOC_input.shape)\n",
    "print(AMOCindex_input.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2c026e-d172-4796-a5d9-ade9dbe1d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAIN TEST SPLIT ###\n",
    "\n",
    "# AMOC_input_train, AMOC_input_test = tf.split(\n",
    "#     tf.random.shuffle(AMOC_input, seed = seed), [AMOC_input.shape[0] * 0.8, AMOC_input.shape[0] * 0.2], axis=0\n",
    "# )\n",
    "\n",
    "AMOC_input_train, AMOC_input_test, AMOCindex_input_train, AMOCindex_input_test, target_train, target_test = train_test_split(AMOC_input, AMOCindex_input, target, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a917c8-eb56-4dd8-b107-246f2a3e9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITY FUNCTIONS FOR VAE CREATION ###\n",
    "\n",
    "def sampling(args):\n",
    "    # z_log_sigma: log sigma^2, this way could guarantee sigma^2 to be positive\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, tf.shape(z_mean)[1], tf.shape(z_mean)[2]), mean=0., stddev=1.)\n",
    "\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "def vae_loss(original, out, z_mean, z_log_sigma, tuning1=1.0, tuning2=1.0, tuning3=1.0, tuning4=1.0):\n",
    "    batch_size = tf.cast(tf.shape(z_mean)[0], tf.float32)\n",
    "    \n",
    "    diff1 = out[:, 1:, :] - out[:, :(-1), :]\n",
    "    diff2 = diff1[:, 1:, :] - diff1[:, :(-1), :]\n",
    "    \n",
    "    # smoothness factor to help make output smooth, square diff of 0/1st/2nd order differentiation\n",
    "    smoothness1 = K.mean(K.square(diff1)) * tuning1\n",
    "    smoothness2 = K.mean(K.square(diff2)) * tuning2\n",
    "    # SSE and KL-divergence.\n",
    "    reconstruction = K.sum(K.square(original - out)) * tuning3\n",
    "    kl = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)) * tuning4\n",
    "\n",
    "    return (smoothness1 + smoothness2 + reconstruction + kl)/batch_size\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters=8, kernel_size=60, strides=4, padding='same', activation='relu'):\n",
    "    \"\"\"\n",
    "        Define de-convolutional layer use Conv2DTranspose\n",
    "        \n",
    "        input_tensor: tensor, with the shape (batch_size, time_steps, dims)\n",
    "        filters: int, output dimension, i.e. the output tensor will have the shape of (batch_size, time_steps, filters)\n",
    "        kernel_size: int, size of the convolution kernel\n",
    "        strides: int, convolution step size\n",
    "        padding: 'same' | 'valid'\n",
    "    \"\"\"\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "#     x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding, activation=activation)(x)\n",
    "    x = Conv2DTranspose(filters, (kernel_size, 1), strides=(strides, 1), padding=padding, activation=activation)(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87997bab-b50a-41a1-8740-6768180d5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(shape_1, shape_2, shape_target, tuning4_para = 4.5):\n",
    "    #latent_dim should be specified by conv1D output shape\n",
    "\n",
    "    ### encoder ###\n",
    "    \n",
    "    inp_AMOC = Input(shape = shape_1) # (batch_size, 179, 1)\n",
    "    inp_AMOCindex = Input(shape = shape_2) # (batch_size, 1680, 1)\n",
    "    AMOC_target = Input(shape = shape_target) # (batch_size, 1680, 1)\n",
    "\n",
    "    enc_AMOC_1 = Conv1D(filters=8, strides=4, kernel_size=60, activation='relu', padding='same', input_shape=(inp_AMOC.shape[1:]))(\n",
    "        inp_AMOC) # (batch_size, 45, 8)\n",
    "    enc_AMOC_2 = Conv1D(filters=8, strides=3, kernel_size=60, activation='relu', padding='same')(enc_AMOC_1) # (batch_size, 15, 8)\n",
    "    enc_AMOC_3 = Conv1D(filters=8, strides=3, kernel_size=60, activation='relu', padding='same')(enc_AMOC_2) # (batch_size, 5, 8)\n",
    "\n",
    "    enc_AMOCindex_1 = Conv1D(filters=8, strides=7, kernel_size=60, activation='relu', padding='same', input_shape=(inp_AMOCindex.shape[1:]))(\n",
    "        inp_AMOCindex) # (batch_size, 240, 8)\n",
    "    enc_AMOCindex_2 = Conv1D(filters=8, strides=4, kernel_size=60, activation='relu', padding='same')(enc_AMOCindex_1) # (batch_size, 60, 8)\n",
    "    enc_AMOCindex_3 = Conv1D(filters=8, strides=4, kernel_size=60, activation='relu', padding='same')(enc_AMOCindex_2) # (batch_size, 15, 8)\n",
    "    enc_AMOCindex_4 = Conv1D(filters=8, strides=3, kernel_size=60, activation='relu', padding='same')(enc_AMOCindex_3) # (batch_size, 5, 8)\n",
    "\n",
    "    enc_out = Concatenate(axis=2)([enc_AMOC_3] + [enc_AMOCindex_4]) # (batch_size, 5, 16)\n",
    "\n",
    "    z_mean = Dense(8)(enc_out) # (batch_size, 5, 8)\n",
    "    z_log_sigma = Dense(8)(enc_out) # (batch_size, 5, 8)\n",
    "\n",
    "    encoder = Model([inp_AMOC, inp_AMOCindex], [z_mean, z_log_sigma])\n",
    "\n",
    "    ### decoder ###\n",
    "\n",
    "    inp_z = Input(shape=z_mean.shape[1:]) # (batch_size, 5, 8)\n",
    "\n",
    "    conv_1 = Conv1DTranspose(inp_z, filters=8, kernel_size=30, strides=7, padding='same', activation='relu') # (batch_size, 35, 8)\n",
    "    conv_2 = Conv1DTranspose(conv_1, filters=8, kernel_size=60, strides=4, padding='same', activation='relu') # (batch_size, 140, 8)\n",
    "    conv_3 = Conv1DTranspose(conv_2, filters=8, kernel_size=60, strides=4, padding='same', activation='relu') # (batch_size, 560, 8)\n",
    "    conv_4 = Conv1DTranspose(conv_3, filters=8, kernel_size=60, strides=3, padding='same', activation='linear') # (batch_size, 1680, 8)\n",
    "\n",
    "    out = Dense(1)(conv_4) # (batch_size, 1680, 1)\n",
    "\n",
    "    decoder = Model([inp_z], [out])\n",
    "\n",
    "    ### encoder + decoder ###\n",
    "\n",
    "    z_mean, z_log_sigma = encoder([inp_AMOC, inp_AMOCindex])\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    pred = decoder([z])\n",
    "\n",
    "    vae = Model([inp_AMOC, inp_AMOCindex, AMOC_target], pred)\n",
    "    vae.add_loss(vae_loss(AMOC_target, pred, z_mean, z_log_sigma, tuning1=0, tuning2=0, tuning3=1.0, tuning4=tuning4_para))\n",
    "    vae.compile(loss=None, optimizer=Adam(learning_rate=1e-3))\n",
    "\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb76d82-83f4-4c99-8185-b2b4997b9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(seed)\n",
    "# es = [\n",
    "#     EarlyStopping(patience=10, verbose=1, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True),\n",
    "#     ModelCheckpoint(filepath='best_model.hdf5', save_freq='epoch', save_best_only=True)]\n",
    "# vae = get_model(AMOC_input.shape[1:], AMOCindex_input.shape[1:], target.shape[1:])\n",
    "# history = vae.fit([AMOC_input_train, AMOCindex_input_train, target_train], batch_size=128, epochs=150, validation_split=0.2, shuffle=False, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ca48d-bf5a-4fd7-92b9-3d8cf0700101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize Model Training History\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('Model loss for tuning4:' + str(para))\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'validation'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1635afb-2f3e-424b-9a89-b01202b1dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid serach to find the best ratio between mse loss and KL-divergence in vae loss, the ratio is controlled by tuning parameter 4 in self-defined vae loss.\n",
    "grid_result = {}\n",
    "\n",
    "epoch_num = 150\n",
    "verbose = 0\n",
    "tuning4_grid = [1e-10, 1e-8, 1e-6, 1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 1e1, 1e2]\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 5, ncols = 3, figsize = (20,30))\n",
    "\n",
    "for i, para in enumerate(tuning4_grid):\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(seed)\n",
    "    es = [\n",
    "    EarlyStopping(patience=10, verbose=verbose, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=file+'best_model_'+'tuning_'+str(para)+'.hdf5', save_freq='epoch', save_best_only=True)]\n",
    "    vae_grid = get_model(AMOC_input.shape[1:], AMOCindex_input.shape[1:], target.shape[1:], tuning4_para = para)\n",
    "    history = vae_grid.fit([AMOC_input_train, AMOCindex_input_train, target_train], batch_size=128, epochs=epoch_num, validation_split=0.2, verbose=verbose, shuffle=False, callbacks=es)\n",
    "    grid_result[para] = min(history.history['val_loss'])\n",
    "    \n",
    "    # Visualize Model Training History\n",
    "    axs[i//3, i%3].plot(history.history['loss'])\n",
    "    axs[i//3, i%3].plot(history.history['val_loss'])\n",
    "    axs[i//3, i%3].set_title('Model loss for tuning4:' + str(para))\n",
    "    axs[i//3, i%3].set_ylabel('loss')\n",
    "    axs[i//3, i%3].set_xlabel('epoch')\n",
    "    axs[i//3, i%3].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig('hyper_tuning/history.png', bbox_inches='tight')\n",
    "# np.save('hyper_tuning/grid_result.npy', grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "726c4f43-21cb-4a0e-b9ac-c3a2d6fc686b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check: grid_result is a dictionary, need better saving mode\n",
    "# grid_result = np.load(file + 'grid_result.npy')\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "for key in grid_result:\n",
    "    plt.plot(math.log10(key), math.log10(grid_result[key]), marker = 'o')\n",
    "plt.title('hyperparameter tuning')\n",
    "plt.ylabel('log loss')\n",
    "plt.xlabel('log(tuning parameter 4)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d1f0b42-5163-4525-a065-42f9e2585a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAFNCAYAAABsXEqqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAfhElEQVR4nO3de5wfdX3v8debJJKUSyISJIA1goCXFoET6eEgR20qeKNYrbfWS1tb1KM1cEQFPSLF9lFbVMypVg8WKp5DtSggIlbQFG/1GgIGLDeNKIQEgki4mIRcPueP3yz+EndDNuzsLzv7ej4e+9iZ73xnvp/ZTfa9c9mZVBWSJHXFToMuQJKksWSwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDbtsJLckuT3Bl2H2pXkj5NcMeg61B0Gm9RhSf4kyTd35G1W1flVdcxYbU8y2KStSDJ1R95e2yZavRIYbNrxHZpkaZLVSf41yXSAJNclOW6oU5JpSe5KcmiSuUkqyQlJbk+yIslb+/rulOSUJD9O8vMkFyTZo1k2tO7rkvwM+Pdt2N4RSb6d5J5m2YeTPKpveSV5U5KbgZubtoVJbk1yb5Krkhzd1//0JJ9J8v+S3Jfk2iQHJTk1yZ3Nesf09Z+Z5Jxm7OVJ/jrJlCRPBj4GHJnk/iT3NP13TvL+JD9LckeSjyWZ0Sx7VpLbkrwjyUrgn/u/GVvZ5leT/Hlfv82O6pqvwRuS3JzkF0k+kiTb0XdKkg803+ufJHlz098A1kMMNu3oXgY8F3gCcAjwJ037J4FX9fV7PrCiqq7pa3s2cCBwDHBK3/W6twAvAp4J7AP8AvjIFuM+E3gycOw2bG8jcBKwJ3AkMB/4H1ts70XA7wBPaea/DxwK7AH8C/CZodBuHAf8X+DRwNXA5fT+v+4LnAH8n76+5wEbgCcChzX1/XlVXQ+8Afh2Ve1aVbOa/n8HHNSM/8Rmm6f1bW/vpq7HAyf078RWtrktXgg8HXgave/rsdvR9y+A5zW1H07v6yptrqr88GOH/ABuAV7VN//3wMea6X2A+4Ddm/nPAm9vpucCBTxpi3XPaaavB+b3LZsDrAem9q27f9/yrW5vmLpPBC7umy/gdx9mX38BPK2ZPh34ct+y44D7gSnN/G7NNmcBjwXWATP6+r8SuLKZ/hPgm33LAjwAHNDXdiTwk2b6WcCDwPSt1LrZNpu2r9IL02H7NPU+o2/+AuCU7ej778Dr+5b9XtN/6qD/vfqx43x4+K4d3cq+6V/SCzSq6vYk/wG8JMnF9H6LX7DFurf2Tf8U+O1m+vHAxUk29S3fSC8khlt3q9tLchDwQWAe8Bv0AvKqraxLcyrzz5v9KWB3ekd8Q+7om14D3FVVG/vmAXZt1p8GrGjO1kHvyG64+gFmNzVe1dc/wJS+Pquqau0I6z8SW34vd92Ovvuw+b6NtJ+axDwVqYnsPHqnI19K79TY8i2WP65v+jeB25vpW4HnVdWsvo/pW6w/3GsvRtreR4EbgAOranfgnfTCot9D22uup72D3im2R1fvdN7qYdbZFrfSO2Lbs29fdq+qp46wH3fRC8an9vWfWVX9IfNwr/wYbvkD9AJzyN6j2IfRWAHs1zf/uJE6avIy2DSRfY7edZYF9K65bendSX4jyVOBPwX+tWn/GPA3SR4PkGR2kuO3YbyRtrcbcC9wf5InAW98mO3sRu+a2CpgapLT6B2xjVpVrQCuAD6QZPfmxpgDkjyz6XIHsN/QzSxVtQn4OHBWkr0AkuybZGvXu7a02TYb1wAvbr4+TwRetz37sw0uABY0Nc+i9wuCtBmDTRNWVa0BLqR3Y8lFw3T5GvAjYBHw/qoa+iPghcDngSuS3Ad8h96NHQ9npO2dDPwRvWt+H+dXgTeSy4F/A26id0pzLY/slNprgEcB/0nvWt1n6V03hN41qR8CK5Pc1bS9o9mP7yS5F/gKcPAoxhtum2fRuzZ3B70j6fO3e2+27uP0gnwpvZtqvkjvl4SNW1tJk0uqfNGoJq7maOegqnpVX9tc4CfAtKraMAZjjOn2NHaSPI/eDUWPH3Qt2nF4xKYJq/nbs9cBZw+6Fo2PJDOSPD/J1CT7Au8BLh50XdqxGGyakJL8Bb3Td/9WVV8fdD0aNwH+it4p16vp/enGaVtdQ5OOpyIlSZ3iEZskqVMMNklSp0yIJ4/sueeeNXfu3EGXIUnagVx11VV3VdXsLdsnRLDNnTuXxYsXD7oMSdIOJMlPh2v3VKQkqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02SJpulF8BZvwWnz+p9XnrBuAx72bLLOOazx3DIeYdwzGeP4bJll7UyzoT4A21J0hhZegFc+hZYv6Y3v/rW3jzAIS9rbdjLll3G6d86nbUb1wKw4oEVnP6t0wF4wf4vGNOxPGKTpMlk0Rm/CrUh69f02lu0cMnCh0JtyNqNa1m4ZOGYj2WwSdJksvq20bWPkZUPrBxV+yNhsEnSZDJzv9G1j5G9d9l7VO2PhMEmSZPJ/NNg2ozN26bN6LW3aMHhC5g+ZfpmbdOnTGfB4QvGfCxvHpGkyWToBpFFZ/ROP87crxdqLd44Ar+6QWThkoWsfGAle++yNwsOXzDmN44ApKrGfKNjbd68eeVrayRJ/ZJcVVXztmz3VKQkqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmd0lqwJXlckiuTXJ/kh0kWNO2nJ1me5Jrm4/lt1SBJmnymtrjtDcBbq2pJkt2Aq5J8uVl2VlW9v8WxJUmTVGvBVlUrgBXN9H1Jrgf2bWs8SZJgnK6xJZkLHAZ8t2l6c5KlSc5N8ujxqEGSNDm0HmxJdgUuBE6sqnuBjwIHAIfSO6L7wAjrnZBkcZLFq1atartMSVJHtBpsSabRC7Xzq+oigKq6o6o2VtUm4OPAEcOtW1VnV9W8qpo3e/bsNsuUJHVIm3dFBjgHuL6qPtjXPqev2x8A17VVgyRp8mnzrsijgFcD1ya5pml7J/DKJIcCBdwCvL7FGiRJk0ybd0V+E8gwi77Y1piSJPnkEUlSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJndJasCV5XJIrk1yf5IdJFjTteyT5cpKbm8+PbqsGSdLk0+YR2wbgrVX1ZOC/Am9K8hTgFGBRVR0ILGrmJUkaE60FW1WtqKolzfR9wPXAvsDxwHlNt/OAF7VVgyRp8hmXa2xJ5gKHAd8FHltVK6AXfsBe41GDJGlyaD3YkuwKXAicWFX3jmK9E5IsTrJ41apV7RUoSeqUVoMtyTR6oXZ+VV3UNN+RZE6zfA5w53DrVtXZVTWvqubNnj27zTIlSR3S5l2RAc4Brq+qD/Yt+jzw2mb6tcAlbdUgSZp8pra47aOAVwPXJrmmaXsn8D7ggiSvA34GvLTFGiRJk0xrwVZV3wQywuL5bY0rSZrcfPKIJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROaS3Ykpyb5M4k1/W1nZ5keZJrmo/ntzW+JGlyavOI7RPAc4dpP6uqDm0+vtji+JKkSai1YKuqrwN3t7V9SZKGM4hrbG9OsrQ5VfnoAYwvSeqwbQq2JAuS7J6ec5IsSXLMdoz3UeAA4FBgBfCBrYx5QpLFSRavWrVqO4aSJE1G23rE9mdVdS9wDDAb+FPgfaMdrKruqKqNVbUJ+DhwxFb6nl1V86pq3uzZs0c7lCRpktrWYEvz+fnAP1fVD/ratlmSOX2zfwBcN1JfSZK2x9Rt7HdVkiuAJwCnJtkN2LS1FZJ8CngWsGeS24D3AM9KcihQwC3A67ezbkmShrWtwfY6etfFllXVL5PsQe905Iiq6pXDNJ8zyvokSRqVbT0VeSRwY1Xdk+RVwP8CVrdXliRJ22dbg+2jwC+TPA14O/BT4JOtVSVJ0nba1mDbUFUFHA8srKqFwG7tlSVJ0vbZ1mts9yU5FXg1cHSSKcC09sqSJGn7bOsR28uBdfT+nm0lsC9wZmtVSZK0nbYp2JowOx+YmeSFwNqq8hqbJGmHs62P1HoZ8D3gpcDLgO8m+cM2C5MkaXts6zW2dwFPr6o7AZLMBr4CfLatwiRJ2h7beo1tp6FQa/x8FOtKkjRutvWI7UtJLgc+1cy/HPAloZI0QXzu6uWcefmN3H7PGvaZNYO3HXswLzps30GX1YptCraqeluSlwBH0Xv48dlVdXGrlUmSxsTnrl7OqRddy5r1GwFYfs8aTr3oWoBOhtu2HrFRVRcCF7ZYiySpBWdefuNDoTZkzfqNnHn5jZMv2JLcR+9J/L+2CKiq2r2VqiRJY+b2e9aMqn2i22qwVZWPzZKkCW6fWTNYPkyI7TNrxgCqaZ93NkpSx73t2IOZMW3KZm0zpk3hbccePKCK2rXN19gkSRPT0HU074qUJHXGiw7bt7NBtiVPRUqSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjqltWBLcm6SO5Nc19e2R5IvJ7m5+fzotsaXJE1ObR6xfQJ47hZtpwCLqupAYFEzL0nSmGkt2Krq68DdWzQfD5zXTJ8HvKit8SVJk9N4X2N7bFWtAGg+7zXO40uSOm6HvXkkyQlJFidZvGrVqkGXI0maIMY72O5IMgeg+XznSB2r6uyqmldV82bPnj1uBUqSJrbxDrbPA69tpl8LXDLO40uSOq7N2/0/BXwbODjJbUleB7wPeE6Sm4HnNPOSJI2ZqW1tuKpeOcKi+W2NKUnSDnvziCRJ28NgkyR1isEmSeoUg02S1Cmt3TwiSRofF668m79dtoLl69az787TOHX/Obxk7z0GXdbAGGySNIFduPJuTr7xVtZsKgBuW7eek2+8FWDShpunIiVpAvvbZSseCrUhazYVf7tsxYAqGjyDTZImsOXr1o+qfTIw2CRpAtt352mjap8MDDZJmsBO3X8OM3bKZm0zdgqn7j9nQBUNnjePSNIENnSDiHdF/orBJkkT3Ev23mNSB9mWPBUpSeoUg02S1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTZLUKQabJKlTDDZJUqcYbJKkTjHYJEmdYrBJkjrFYJMkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROmTroAiRJW7di5SUs+/H7WbtuBdN3nsP+B5zMnL2PH3RZOyyDTZJ2YCtWXsINN7yLTZvWALB23e3ccMO7AAy3EQzkVGSSW5Jcm+SaJIsHUYMkTQTLfvz+h0JtyKZNa1j24/cPqKId3yCP2J5dVXcNcHxJ2uGtXbdiVO3y5hFJ2qFN33nOqNo1uGAr4IokVyU5YUA1SNIOb/8DTmannWZs1rbTTjPY/4CTB1TRjm9QpyKPqqrbk+wFfDnJDVX19f4OTeCdAPCbv/mbg6hRkgZu6AYR74rcdqmqwRaQnA7cX1UjXgmdN29eLV7sPSaSpF9JclVVzduyfdxPRSbZJcluQ9PAMcB1412HJKmbBnEq8rHAxUmGxv+XqvrSAOqQJHXQuAdbVS0Dnjbe40qSJgdv95ckdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsU3aEvSAC1dupRFixaxevVqZs6cyfz58znkkEMGXdaEZrBJ0oAsXbqUSy+9lPXr1wOwevVqLr30UgDD7RHwVKQkDciiRYseCrUh69evZ9GiRQOqqBsMNkkakNWrV4+qXdvGYJOkAZk5c+ao2rVtDDZJGpD58+czbdq0zdqmTZvG/PnzB1RRN3jziCQNyNANIt4VObYMNkkaoEMOOcQgG2OeipQkdYrBJknqFINNktQpBpskqVMMNklSpxhskqROMdgkSZ1isEmSOsVgkyR1isEmSeoUg02S1CkGmySpUww2SVKnGGySpE7xtTWSBDxw9Z3ce/ktbLxnHVNm7czux85ll8P2GnRZ2g4Gm6RJ74Gr7+Sei26m1m8CYOM967jnopsBDLcJyFORkia9ey+/5aFQG1LrN3Hv5bcMpiA9IgabpElv4z3rRtWuHZunIqUJYPWll3LnWR9iw4oVTJ0zh71OOpGZxx036LJacf03ruQbn/4k9/38LnZ7zJ4c/YrX8OSjn93qmFNm7TxsiE2ZtXOr46odAwm2JM8FFgJTgH+qqve1Od7nrl7OmZffyO33rGGfWTN427EH86LD9m1zyMFZegEsOgNW3wYz94P5p8EhLxt0Va24bNllLFyykJUPrGTvXfZmweELeMH+Lxh0WWNu9aWXsuLdp1Fr1wKw4fbbWfHu0wBaD7ebvruSb1/yY+6/ex277rEzRx5/AAf9zt6tjXf9N67kirM/zIYHeyFz312ruOLsDwO0Gm67Hzt3s2tsAJm2E7sfO7e1MdWecT8VmWQK8BHgecBTgFcmeUpb433u6uWcetG1LL9nDQUsv2cNp150LZ+7enlbQw7O0gvg0rfA6luB6n2+9C299o65bNllnP6t01nxwAqKYsUDKzj9W6dz2bLLBl3amLvzrA89FGpDau1a7jzrQ62Oe9N3V3Ll+Tdw/929kLn/7nVcef4N3PTdla2N+Y1Pf/KhUBuy4cF1fOPTn2xtTOjdIDLrxQc+dIQ2ZdbOzHrxgd44MkEN4hrbEcCPqmpZVT0IfBo4vq3Bzrz8Rtas37hZ25r1Gznz8hvbGnJwFp0B69ds3rZ+Ta+9YxYuWcjajZv/sF+7cS0LlywcUEXt2bBixajax8q3L/kxGx7c/IaKDQ9u4tuX/Li1Me/7+V2jah9Luxy2F3NOOYL93nc0c045wlCbwAYRbPsCt/bN39a0teL2e9aMqn1CW33b6NonsJUPDH/UMFL7RDZ1zpxRtY+VoSO1bW0fC7s9Zs9RtUvDGUSwZZi2+rVOyQlJFidZvGrVqu0ebJ9ZM0bVPqHN3G907RPY3rsMf51npPaJbK+TTiTTp2/WlunT2eukE1sdd9c9hr9xYqT2sXD0K17D1Edtvv2pj9qZo1/xmtbGVPcMIthuAx7XN78fcPuWnarq7KqaV1XzZs+evd2Dve3Yg5kxbcpmbTOmTeFtxx683dvcYc0/DaZtEdjTZvTaO2bB4QuYPmXzH/bTp0xnweELBlRRe2Yedxxz3nsGU/fZBxKm7rMPc957Rus3jhx5/AFMfdTmPyKmPmonjjz+gNbGfPLRz+aYE97MbnvOhoTd9pzNMSe8ufW7ItUtqfq1g6V2B0ymAjcB84HlwPeBP6qqH460zrx582rx4sXbPaZ3RXpXpLbPeN8VKY1Gkquqat6vtY93sDXFPB/4EL3b/c+tqr/ZWv9HGmySpO4ZKdgG8ndsVfVF4IuDGFuS1G0+UkuS1CkGmySpUww2SVKnGGySpE4x2CRJnWKwSZI6xWCTJHXKQP5Ae7SSrAJ+Ogab2hNo/zHhOwb3tZvc1+6aTPs7Vvv6+Kr6tWcuTohgGytJFg/3V+pd5L52k/vaXZNpf9veV09FSpI6xWCTJHXKZAu2swddwDhyX7vJfe2uybS/re7rpLrGJknqvsl2xCZJ6rjOB1uSlyb5YZJNSeZtsezUJD9KcmOSYwdVY1uSHJrkO0muSbI4yRGDrqlNSf6y+V7+MMnfD7qetiU5OUkl2XPQtbQlyZlJbkiyNMnFSWYNuqaxluS5zb/bHyU5ZdD1tCXJ45JcmeT65v9oa6+773ywAdcBLwa+3t+Y5CnAK4CnAs8F/jHJlPEvr1V/D/xVVR0KnNbMd1KSZwPHA4dU1VOB9w+4pFYleRzwHOBng66lZV8GfquqDgFuAk4dcD1jqvmZ8xHgecBTgFc2P5u6aAPw1qp6MvBfgTe1ta+dD7aqur6qbhxm0fHAp6tqXVX9BPgR0LUjmgJ2b6ZnArcPsJa2vRF4X1WtA6iqOwdcT9vOAt5O73vcWVV1RVVtaGa/A+w3yHpacATwo6paVlUPAp+m97Opc6pqRVUtaabvA64H9m1jrM4H21bsC9zaN38bLX2RB+hE4Mwkt9I7gunUb7tbOAg4Osl3k3wtydMHXVBbkvw+sLyqfjDoWsbZnwH/Nugixthk+Dn0a5LMBQ4DvtvG9qe2sdHxluQrwN7DLHpXVV0y0mrDtE243363tu/AfOCkqrowycuAc4DfG8/6xtLD7OtU4NH0TnE8Hbggyf41QW/7fZh9fSdwzPhW1J5t+f+b5F30TmWdP561jYNO/BwajSS7AhcCJ1bVvW2M0Ylgq6rt+WF9G/C4vvn9mICn6ra270k+CQxdoP0M8E/jUlRLHmZf3whc1ATZ95Jsovc8ulXjVd9YGmlfk/w28ATgB0mg9+92SZIjqmrlOJY4Zh7u/2+S1wIvBOZP1F9UtqITP4e2VZJp9ELt/Kq6qK1xJvOpyM8Dr0iyc5InAAcC3xtwTWPtduCZzfTvAjcPsJa2fY7ePpLkIOBRdPCBslV1bVXtVVVzq2ouvR+Mh0/UUHs4SZ4LvAP4/ar65aDracH3gQOTPCHJo+jd0Pb5AdfUivR+EzsHuL6qPtjmWJ04YtuaJH8A/AMwG7gsyTVVdWxV/TDJBcB/0jvF8aaq2jjIWlvwF8DCJFOBtcAJA66nTecC5ya5DngQeG0Hf7ufjD4M7Ax8uTlC/U5VvWGwJY2dqtqQ5M3A5cAU4Nyq+uGAy2rLUcCrgWuTXNO0vbOqvjjWA/nkEUlSp0zmU5GSpA4y2CRJnWKwSZI6xWCTJHWKwSZJ6hSDTRNekvsf4fqfTbJ/M/3OR7iteUn+9yPZxo4uydwkfzSG2/t882caQ/PvT/K7Y7V9TT4Gmya1JE8FplTVsqbpEQVbVS2uqrc88soemZbfVDEXGFWwjVRPkhcDW/5i8g9AZ1/fovYZbOqM9JyZ5Lok1yZ5edO+U5J/bN4B9YUkX0zyh81qfwwMPY/wfcCM5v115zdHJv1HEicnOb2Z/mqSv0vyvSQ3JTm6aX9Wki8006cnObfpuyzJW/q29e7mPWNfTvKpJCcPsz+fSPKxJN9oxnhh0z63aVvSfPy3vrGvTPIvwLVN2+eSXNXs+wl9276/qf+qJF9JckRfnb/f9JnSfD2/n9770F7frP4+eg+cvibJSSP1G66eLfZvV+B/An/d315VPwUek2S450dKD6vzTx7RpPJi4FDgafSeE/n9JF+n98SDucBvA3vRe13Guc06RwGfAqiqU5K8uXl/3dATyLdmalUdkeT5wHsY/gHTTwKeDewG3Jjko019L6H3dPOpwBLgqhHGmEvvsWgHAFcmeSJwJ/Ccqlqb5MCm/qGX6B5B7/1lP2nm/6yq7k4yo/l6XFhVPwd2Ab5aVe9IcjG9cHkOvXeCnUfvsU6vA1ZX1dOT7Az8R5Ir6B1NnVxVQ0F7wgj9hqun33uBDwDDPSprCb3vzYUjfF2kERls6pJnAJ9qHo12R5Kv0XvS/zOAz1TVJmBlkiv71pnD9j8oeeghrlfRC6DhXNa8I25dkjuBxzb1XFJVawCSXLqVMS5o6r45yTJ6QfkT4MNJDgU20ntlz5DvbREib2keKwe9h+0eCPyc3mPHvtS0Xwusq6r1Sa7t25djgEP6jm5nNus/uEWNW+u3ZT00+3wo8MSqOmmEXyDuBPYZpl16WAabumS4V4BsrR1gDTB9hGUb2Px0/Zb91jWfNzLy/6V1fdND/bZWz5a2fOZdAScBd9A78tuJ3nNAhzwwNJHkWfSOIo+sql8m+Sq/2of1fc/S3DRUZ1VtSu/ZojR1/mVVXd5fQLPdzZq20u8Bhnck8F+S3ELva7JXkq9W1dC2p9P73kij5jU2dcnXgZc313xmA/+d3hsbvgm8pLnW9ljgWX3rXA88sW9+fXqv1oBeeOyV5DHNKbYXjlGd3wSOSzK9uc70gq30fWlT9wHA/sCN9I6IVjRHcq+m9/Dc4cwEftGE2pPovatuNC4H3jj09UhyUJJdgPvonVp9uH4jqqqPVtU+zRsKngHc1Bdq0DsKvW64daWH4xGbuuRiekcCP6B3ZPP2qlqZ5EJ6L129DriJ3lt7VzfrXEYv6L7SzJ8NLE2ypKr+OMkZTf+fADeMRZFV9f0kn2/q/CmwuK+eLd0IfI3eKcw3NNfV/hG4MMlLgSsZ+ajoS8AbkixttvOdUZb6T/ROSy5JEnqnbF8ELAU2JPkB8Alg4Qj9tksTkE+k93WRRs2n+2tSSLJrVd2f5DH0juKOakJvBr1wOGo8X1vUV89v0DvSPKGqlmzR5xPAF6rqs+NV146guSZ4eFW9e9C1aGLyiE2TxReSzKL3AtL3Dr2Ys6rWJHkPsC/ws3Gs5+wkT6F3Lem8LUNtkptK725Jabt4xCZJ6hRvHpEkdYrBJknqFINNktQpBpskqVMMNklSpxhskqRO+f/hsinESn6yhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "for key in grid_result:\n",
    "    plt.plot(math.log10(key), grid_result[key], marker = 'o')\n",
    "plt.title('hyperparameter tuning')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('log(tuning parameter 4)')\n",
    "# plt.ylim((0, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eecafab0-7256-47ad-a89e-b258c63c2685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_para = 4.5\n",
    "best_para = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e19bc-0c9f-484e-9a79-092a6f82d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = load_model('hyper_tuning/best_model_'+'tuning_'+str(best_para)+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd7cac2-ed52-4aac-b611-547638994181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to save model output: folder 'model_output' will not be shown on git \n",
    "# repo as the file is large, no need to git it.\n",
    "file = '../model_output/beta_' + str(best_para) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa38b4-93be-4206-bff5-3bb2e4bd8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: prediction for test data set 'test_pred' need 421. GiB memory, \n",
    "# ensure have enough space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf4f89-3823-4fe4-b64f-9fcdec8a13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pred testing data set, prediction results should be in original scale\n",
    "test_pred = np.zeros((1000, target_test.shape[0], target_test.shape[1], target_test.shape[2]))\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "for i in range(1000):\n",
    "    test_pred[i, :, :, :] = AMOC_scaler.inverse_transform(vae.predict([AMOC_input_test, AMOCindex_input_test, np.zeros(target_test.shape)], verbose = 0))\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d174e-4fff-4b04-9479-878afa0dfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ATTENTION: prediction for test data set 'test_pred' need 421. GiB memory, \n",
    "# # ensure have enough space.\n",
    "\n",
    "# np.save(file + 'test_pred.npy', test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6898c-7a52-481d-b52a-867dca507f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot some case in testing data set\n",
    "\n",
    "# i = 11000\n",
    "\n",
    "# test_pred_1000 = test_pred[:, i, :, :]\n",
    "# AMOC_input_test_0 = AMOC_scaler.inverse_transform(AMOC_input_test[i, :, :])\n",
    "# AMOCindex_input_test_0 = AMOC_scaler.inverse_transform(AMOCindex_input_test[i, :, :])\n",
    "# target_test_0 = AMOC_scaler.inverse_transform(target_test[i, :, :])\n",
    "\n",
    "# test_pred_1000 = np.squeeze(test_pred_1000)\n",
    "# AMOC_input_test_0 = np.squeeze(AMOC_input_test_0)\n",
    "# AMOCindex_input_test_0 = np.squeeze(AMOCindex_input_test_0)\n",
    "# target_test_0 = np.squeeze(target_test_0)\n",
    "\n",
    "# ### confidence interval ###\n",
    "# test_pred_1000 = np.squeeze(test_pred_1000)\n",
    "# mean = np.mean(test_pred_1000, axis=0)\n",
    "# std = np.std(test_pred_1000, axis=0)\n",
    "# x = np.linspace(1, test_pred_1000.shape[1], test_pred_1000.shape[1])\n",
    "# ci = 1.96 * std\n",
    "\n",
    "# mask = np.array(~AMOC_Obs['Obs'].isna())\n",
    "\n",
    "# foo = plt.figure(figsize=(15, 5))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.tight_layout(pad = 2)\n",
    "# for j in range(6):\n",
    "#     plt.plot(x[mask][j], AMOC_input_test_0[j], c='red', marker='x')\n",
    "# plt.plot(x[mask][6:], AMOC_input_test_0[6:], c='red', label='Observations')\n",
    "# plt.plot(target_test_0, c='blue', label='True mean trend')\n",
    "# plt.plot(mean, c='orange', label='Estimated mean trend')\n",
    "# plt.fill_between(x, (mean-ci), (mean+ci), color='navy', alpha=.2)\n",
    "# plt.ylabel(r'AMOC [Strength (Sv)]')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(AMOCindex_input_test_0, c='lightgray', label='AMOC index')\n",
    "# plt.ylabel('Temperature ($^\\circ$C)')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebc872-2481-426a-bd42-31722127fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save some representative testing data case\n",
    "# for i in [0, 1000, 4000, 8000, 10000]:\n",
    "#     np.save(file + 'test_pred_'+str(i)+'.npy', test_pred[:, i, :, :])\n",
    "#     np.save(file + 'AMOC_input_test_'+str(i)+'.npy', AMOC_scaler.inverse_transform(AMOC_input_test[i, :, :]))\n",
    "#     np.save(file + 'AMOCindex_input_test_'+str(i)+'.npy', AMOC_scaler.inverse_transform(AMOCindex_input_test[i, :, :]))\n",
    "#     np.save(file + 'target_test_'+str(i)+'.npy', AMOC_scaler.inverse_transform(target_test[i, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c76ec-ec06-4367-bfd5-177716a7bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pred Observation data, prediction results should be in original scale ###\n",
    "AMOC_Obs = np.array(AMOC_Obs_std.loc[~AMOC_Obs_std['Obs'].isna(), 'Obs']).reshape((1, -1, 1))\n",
    "AMOC_Obs = AMOC_Obs - AMOC_Obs.mean()\n",
    "\n",
    "AMOCindex_Obs = np.array(AMOCindex_Obs_std[['Obs']]).reshape((1, -1, 1))\n",
    "AMOCindex_Obs = AMOCindex_Obs - AMOCindex_Obs.mean()\n",
    "\n",
    "Obs_pred = np.zeros((1000, target_test.shape[1], target_test.shape[2]))\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "for i in range(1000):\n",
    "    Obs_pred_0 = AMOC_scaler.inverse_transform(vae.predict([AMOC_Obs, AMOCindex_Obs, np.zeros((1, target_test.shape[1], target_test.shape[2]))], verbose = 0))\n",
    "    Obs_pred[i, :, :] = np.squeeze(Obs_pred_0, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44844e9d-6a3d-4be6-8731-23cd83303ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.save(file + 'Obs_pred.npy', Obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b70020-44da-495b-a2cb-1ca83303aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get emp_prob: for each testing data set, find confidence interval from 1,000 trails prediction generated from vae, check if target value is in constructed confidence interval. \n",
    "# The ideal empircal probability should be 0.95 as we are constructing 95% CI.\n",
    "# Calculate bias #\n",
    "\n",
    "emp_prob = np.zeros((len(target_test), )) # len(target_test): 33,600\n",
    "test_bias = np.zeros((len(target_test), target_test.shape[1]))\n",
    "\n",
    "for i in range(len(target_test)):\n",
    "    sequence_test_pred_1000 = np.squeeze(test_pred[:, i, :, :])\n",
    "    mean = np.mean(sequence_test_pred_1000, axis=0)\n",
    "    std = np.std(sequence_test_pred_1000, axis=0)\n",
    "    ci = 1.96 * std\n",
    "    lower = mean - ci\n",
    "    upper = mean + ci\n",
    "    target = np.squeeze(AMOC_scaler.inverse_transform(target_test[i, :, :]))\n",
    "    count = sum((target >= lower) & (target <= upper))\n",
    "    emp_prob[i] = count/target_test.shape[1]\n",
    "    \n",
    "    bias = target - mean\n",
    "    test_bias[i, :] = bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403b4fe-5e47-4522-839b-86d71da24897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(file + 'emp_prob.npy', emp_prob)\n",
    "# np.save(file + 'test_bias.npy', test_bias)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Conda 2019.10) [python/3.7-2019.10]",
   "language": "python",
   "name": "python37_201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
