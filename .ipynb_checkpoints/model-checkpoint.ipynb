{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a37fe55-82d9-48a8-ad38-2832b4889e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d287124-145e-4d2f-9ad9-f7dda8da2994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              total        used        free      shared  buff/cache   available',\n",
       " 'Mem:        1548094       23114     1496224        2732       28755     1520094',\n",
       " 'Swap:         49151          46       49105']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%system free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73787f9c-4f0d-487c-8555-a787ac8bc658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the RANGE of AMOC observation is 140\n"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "# Define important input paramaters####################\n",
    "# define the target AMOC range#########################\n",
    "#######################################################\n",
    "\n",
    "AMOC_range = 140\n",
    "\n",
    "print('the RANGE of AMOC observation is', AMOC_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5cebcf-1efa-4ba5-a4fe-b699f4a87784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMOC_140_years/\n"
     ]
    }
   ],
   "source": [
    "path_str = 'AMOC_'+str(AMOC_range)+'_years/'\n",
    "print(path_str)\n",
    "\n",
    "# Input data load path\n",
    "input_file = 'input_data/'+path_str\n",
    "\n",
    "# Hyper-parameter tuning data saving path\n",
    "hyper_path = 'hyper_tuning/'+path_str\n",
    "\n",
    "# large output data saving path\n",
    "outDATA_path = '../model_output/'+path_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f1a5f6-e720-4f0a-aba1-a5bfc164ab72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# change font size plt, need to run two times for old version matplotlib :)\n",
    "\n",
    "# check: https://matplotlib.org/stable/api/matplotlib_configuration_api.html#matplotlib.rcParams for systematically change plot format\n",
    "# font = {'size': 12}\n",
    "plt.rcParams.update({'font.size':16, 'legend.fontsize':12})\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c4f592-5401-4907-ba70-516f2fb73d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size':16, 'legend.fontsize':12})\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcad3a7-761a-40b0-bccd-f1809d988697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe99622-842b-4d2a-b3d4-c6316c12ace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMOC observation data shape: (1680, 2)\n",
      "AMOC index observation data shape: (1680, 2)\n",
      "AMOC Ensemble data shape: (5988, 29)\n",
      "AMOC index Ensemble data shape: (5988, 29)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "AMOC_Obs = pd.read_csv(input_file+'dtdata_AMOC_Obs.csv', index_col = 0)\n",
    "AMOC_Ensemble = pd.read_csv(input_file+'dtdata_AMOC_Ensemble.csv', index_col = 0)\n",
    "\n",
    "AMOCindex_Obs = pd.read_csv(input_file+'dtdata_AMOCindex_Obs.csv', index_col = 0)\n",
    "AMOCindex_Ensemble = pd.read_csv(input_file+'dtdata_AMOCindex_Ensemble.csv', index_col = 0)\n",
    "\n",
    "print('AMOC observation data shape:', AMOC_Obs.shape)\n",
    "print('AMOC index observation data shape:', AMOCindex_Obs.shape)\n",
    "\n",
    "print('AMOC Ensemble data shape:', AMOC_Ensemble.shape)\n",
    "print('AMOC index Ensemble data shape:', AMOCindex_Ensemble.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5f68d84-998a-49b6-80e3-91a64e10e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a debug function to check if data is proper scaled\n",
    "def debug(original_data, scaled_data, scaler):\n",
    "    total_cnt = np.array([1])\n",
    "    for num in original_data.shape:\n",
    "        total_cnt *= num\n",
    "    result = np.sum(np.absolute(original_data - scaler.inverse_transform(scaled_data)) < 1e-5) == total_cnt\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c3c3f7-401d-4640-8cae-53ba0a46f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Input: AMOC is (112000, 179, 1)\n",
      "Shape of Input: AMOC_index is (112000, 1680, 1)\n",
      "Shape of Target is (112000, 1680, 1)\n",
      "Size of train/validation/test data set: (67200, 22400, 22400)\n",
      "AMOC Training data min/max: -22.3077961626257 11.297628080097208\n",
      "AMOC Validation data min/max: -18.15533037572626 10.146398006033515\n",
      "AMOC Testing data min/max: -20.612997406681565 10.228088224301676\n",
      "AMOC_index Training data min/max: -6.54510412579784 6.789500768249779\n",
      "AMOC_index Validation data min/max: -6.501024719250221 6.785845828368826\n",
      "AMOC_index Testing data min/max: -6.532087079964506 6.794051556345016\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "#############PRE-PROCESSING###########################################################\n",
    "######################################################################################\n",
    "\n",
    "# # set seed\n",
    "\n",
    "# tf.random.set_seed(seed)\n",
    "# os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)\n",
    "\n",
    "seed = 1\n",
    "\n",
    "# Generate input data to use in DVAE\n",
    "\n",
    "AMOC = np.array(AMOC_Ensemble[[str(i) for i in range(1, 29)]])\n",
    "AMOC_index = np.array(AMOCindex_Ensemble[[str(i) for i in range(1, 29)]])\n",
    "\n",
    "Ensemble_length = AMOC.shape[0]\n",
    "Obs_length = len(AMOC_Obs)\n",
    "mask = np.array(~AMOC_Obs['Obs'].isna()) # non-missing part in observation data\n",
    "\n",
    "# Randomly sample thousands of different long term time segments from 499 years (5,988 data points) Ensemble data; for each time segment,\n",
    "# there will be 28 different training examples.\n",
    "num_select = (Ensemble_length - Obs_length) // 1000 *1000\n",
    "\n",
    "# start_list: List of start index of time segments from Ensemble data.\n",
    "np.random.seed(seed)\n",
    "start_list = np.random.choice(Ensemble_length - Obs_length, num_select, replace=False)\n",
    "# start_list = [np.random.randint(0, Ensemble_length - Obs_length) for i in range(num_select)] # with replacement\n",
    "\n",
    "# AMOC_input: AMOC data corresponding to observation non-miss part.\n",
    "# AMOCindex_input: AMOC Index data with same time segment corresponding to AMOC\n",
    "# target: AMOC long term trend, generated from 2-degree polynomial fitting of 28 Ensemble trails to filter out nature variability.\n",
    "AMOC_input = []\n",
    "AMOCindex_input = []\n",
    "target = []\n",
    "\n",
    "for start in start_list:\n",
    "    AMOC_seg = AMOC[start:(start + Obs_length), :] # Obs_length * 28\n",
    "    AMOC_seg_masked = AMOC_seg[mask, :] # 179 * 28 (non-missing part length * 28)\n",
    "    \n",
    "    # De-mean AMOC data with mean of non-missing part data, which corresponding to real-world data: only non-missing part is known.\n",
    "    mean = AMOC_seg_masked.mean(axis = 0)\n",
    "    AMOC_seg = AMOC_seg - mean\n",
    "    AMOC_seg_masked = AMOC_seg_masked - mean\n",
    "\n",
    "    # Fit 2-degree polynomial with 28 ensemble trails\n",
    "    x = np.array(range(Obs_length))\n",
    "    # ploy: Polynomial coefficients, highest power first.\n",
    "    poly = np.polyfit(x.repeat(AMOC_seg.shape[1]), AMOC_seg.flatten(), 2)\n",
    "    y = x**2 * poly[0] + x * poly[1] + poly[2]\n",
    "    y = np.reshape(y, (y.shape[0], 1)) # Obs_length * 1\n",
    "    y = y.repeat(AMOC_seg.shape[1], axis = 1) # Obs_length * 28\n",
    "    \n",
    "    # De-mean AMOC index data.\n",
    "    AMOCindex_seg = AMOC_index[start:(start + Obs_length), :]\n",
    "    \n",
    "    mean = AMOCindex_seg.mean(axis = 0)\n",
    "    AMOCindex_seg = AMOCindex_seg - mean\n",
    "\n",
    "    # Reshape data to (number of trails, number of timesteps, dimension)\n",
    "    AMOC_seg_masked = np.reshape(np.ravel(AMOC_seg_masked, order = 'F'), (AMOC_seg_masked.shape[1], AMOC_seg_masked.shape[0], 1))\n",
    "    AMOCindex_seg = np.reshape(np.ravel(AMOCindex_seg, order = 'F'), (AMOCindex_seg.shape[1], AMOCindex_seg.shape[0], 1))\n",
    "    y = np.reshape(np.ravel(y, order = 'F'), (y.shape[1], y.shape[0], 1))\n",
    "    \n",
    "    AMOC_input.append(AMOC_seg_masked)\n",
    "    AMOCindex_input.append(AMOCindex_seg)\n",
    "    target.append(y)\n",
    "    \n",
    "AMOC_input = np.vstack(AMOC_input)\n",
    "AMOCindex_input = np.vstack(AMOCindex_input)\n",
    "target = np.vstack(target)\n",
    "\n",
    "print('Shape of Input: AMOC is', AMOC_input.shape)\n",
    "print('Shape of Input: AMOC_index is', AMOCindex_input.shape)\n",
    "print('Shape of Target is', target.shape)\n",
    "\n",
    "### TRAIN VALIDATION TEST SPLIT : 0.6/0.2/0.2\n",
    "\n",
    "# AMOC_input_train, AMOC_input_test = tf.split(\n",
    "#     tf.random.shuffle(AMOC_input, seed = seed), [AMOC_input.shape[0] * 0.8, AMOC_input.shape[0] * 0.2], axis=0\n",
    "# )\n",
    "\n",
    "# TRAIN TEST SPLIT: 0.8/0.2\n",
    "AMOC_input_train, AMOC_input_test, AMOCindex_input_train, AMOCindex_input_test, target_train, target_test = train_test_split(AMOC_input, AMOCindex_input, target, test_size=0.2, random_state=seed, shuffle=False)\n",
    "\n",
    "# TRAIN VALIDATION SPLIT with TRAIN: 0.75/0.25\n",
    "AMOC_input_train, AMOC_input_val, AMOCindex_input_train, AMOCindex_input_val, target_train, target_val = train_test_split(AMOC_input_train, AMOCindex_input_train, target_train, test_size=0.25, random_state=seed, shuffle=False)\n",
    "\n",
    "print('Size of train/validation/test data set:', (AMOC_input_train.shape[0], AMOC_input_val.shape[0], AMOC_input_test.shape[0]))\n",
    "\n",
    "print('AMOC Training data min/max:', np.min(AMOC_input_train), np.max(AMOC_input_train))\n",
    "print('AMOC Validation data min/max:', np.min(AMOC_input_val), np.max(AMOC_input_val))\n",
    "print('AMOC Testing data min/max:', np.min(AMOC_input_test), np.max(AMOC_input_test))\n",
    "\n",
    "print('AMOC_index Training data min/max:', np.min(AMOCindex_input_train), np.max(AMOCindex_input_train))\n",
    "print('AMOC_index Validation data min/max:', np.min(AMOCindex_input_val), np.max(AMOCindex_input_val))\n",
    "print('AMOC_index Testing data min/max:', np.min(AMOCindex_input_test), np.max(AMOCindex_input_test))\n",
    "\n",
    "# Scaling train/validation/test data according to training data set to prevent information lekage\n",
    "\n",
    "# Define a class\n",
    "class Scaler:\n",
    "    def __init__(self, train_data):\n",
    "        self.min = np.min(train_data)\n",
    "        self.max = np.max(train_data)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return (X - self.min) / (self.max - self.min)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return X * (self.max - self.min) + self.min\n",
    "\n",
    "# Create scaled data for AMOC\n",
    "AMOC_scaler = Scaler(AMOC_input_train)\n",
    "\n",
    "AMOC_input_train_scaled = AMOC_scaler.transform(AMOC_input_train)\n",
    "AMOC_input_val_scaled = AMOC_scaler.transform(AMOC_input_val)\n",
    "AMOC_input_test_scaled = AMOC_scaler.transform(AMOC_input_test)\n",
    "\n",
    "target_train_scaled = AMOC_scaler.transform(target_train)\n",
    "target_val_scaled = AMOC_scaler.transform(target_val)\n",
    "target_test_scaled = AMOC_scaler.transform(target_test)\n",
    "\n",
    "# Create scaled data for AMOC_index\n",
    "AMOCindex_scaler = Scaler(AMOCindex_input_train)\n",
    "\n",
    "AMOCindex_input_train_scaled = AMOCindex_scaler.transform(AMOCindex_input_train)\n",
    "AMOCindex_input_val_scaled = AMOCindex_scaler.transform(AMOCindex_input_val)\n",
    "AMOCindex_input_test_scaled = AMOCindex_scaler.transform(AMOCindex_input_test)\n",
    "\n",
    "# A debugger to test if scaler works right\n",
    "assert debug(AMOC_input_train, AMOC_input_train_scaled, AMOC_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a917c8-eb56-4dd8-b107-246f2a3e9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UTILITY FUNCTIONS FOR VAE CREATION ###\n",
    "\n",
    "def sampling(args):\n",
    "    # z_log_sigma: log sigma^2, this way could guarantee sigma^2 to be positive\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch_size = tf.shape(z_mean)[0]\n",
    "    epsilon = K.random_normal(shape=(batch_size, tf.shape(z_mean)[1], tf.shape(z_mean)[2]), mean=0., stddev=1.)\n",
    "\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon\n",
    "\n",
    "def vae_loss(original, out, z_mean, z_log_sigma, tuning1=1.0, tuning2=1.0, tuning3=1.0, tuning4=1.0):\n",
    "    batch_size = tf.cast(tf.shape(z_mean)[0], tf.float32)\n",
    "    \n",
    "    diff1 = out[:, 1:, :] - out[:, :(-1), :]\n",
    "    diff2 = diff1[:, 1:, :] - diff1[:, :(-1), :]\n",
    "    \n",
    "    # smoothness factor to help make output smooth, square diff of 0/1st/2nd order differentiation\n",
    "    smoothness1 = K.mean(K.square(diff1)) * tuning1\n",
    "    smoothness2 = K.mean(K.square(diff2)) * tuning2\n",
    "    # SSE and KL-divergence.\n",
    "    reconstruction = K.sum(K.square(original - out)) * tuning3\n",
    "    kl = -0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)) * tuning4\n",
    "\n",
    "    return (smoothness1 + smoothness2 + reconstruction + kl)/batch_size\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters=8, kernel_size=60, strides=4, padding='same', activation='relu'):\n",
    "    \"\"\"\n",
    "        Define de-convolutional layer use Conv2DTranspose\n",
    "        \n",
    "        input_tensor: tensor, with the shape (batch_size, time_steps, dims)\n",
    "        filters: int, output dimension, i.e. the output tensor will have the shape of (batch_size, time_steps, filters)\n",
    "        kernel_size: int, size of the convolution kernel\n",
    "        strides: int, convolution step size\n",
    "        padding: 'same' | 'valid'\n",
    "    \"\"\"\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "#     x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding, activation=activation)(x)\n",
    "    x = Conv2DTranspose(filters, (kernel_size, 1), strides=(strides, 1), padding=padding, activation=activation)(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87997bab-b50a-41a1-8740-6768180d5500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(shape_1, shape_2, shape_target, kernel_size = 60, stride_enc = (7,4,4,3), stride_dec = (7,4,4,3), tuning4_para = 1.0):\n",
    "    #latent_dim should be specified by conv1D output shape\n",
    "\n",
    "    ### encoder ###\n",
    "    \n",
    "    inp_AMOC = Input(shape = shape_1) # (batch_size, 179, 1)\n",
    "    inp_AMOCindex = Input(shape = shape_2) # (batch_size, 840, 1)\n",
    "    AMOC_target = Input(shape = shape_target) # (batch_size, 840, 1)\n",
    "    \n",
    "#     print(inp_AMOC.shape)\n",
    "#     print(inp_AMOCindex.shape)\n",
    "#     print(AMOC_target.shape)\n",
    "\n",
    "    enc_AMOC_1 = Conv1D(filters=8, strides=4, kernel_size=kernel_size, activation='relu', padding='same', input_shape=(inp_AMOC.shape[1:]))(\n",
    "        inp_AMOC) # (batch_size, 45, 8)\n",
    "    enc_AMOC_2 = Conv1D(filters=8, strides=3, kernel_size=kernel_size, activation='relu', padding='same')(enc_AMOC_1) # (batch_size, 15, 8)\n",
    "    enc_AMOC_3 = Conv1D(filters=8, strides=3, kernel_size=kernel_size, activation='relu', padding='same')(enc_AMOC_2) # (batch_size, 5, 8)\n",
    "    \n",
    "#     print(enc_AMOC_1.shape)\n",
    "#     print(enc_AMOC_2.shape)\n",
    "#     print(enc_AMOC_3.shape)\n",
    "    \n",
    "    enc_AMOCindex_1 = Conv1D(filters=8, strides=stride_enc[0], kernel_size=kernel_size, activation='relu', padding='same', input_shape=(inp_AMOCindex.shape[1:]))(\n",
    "        inp_AMOCindex) # (batch_size, 120, 8)\n",
    "    enc_AMOCindex_2 = Conv1D(filters=8, strides=stride_enc[1], kernel_size=kernel_size, activation='relu', padding='same')(enc_AMOCindex_1) # (batch_size, 30, 8)\n",
    "    enc_AMOCindex_3 = Conv1D(filters=8, strides=stride_enc[2], kernel_size=kernel_size, activation='relu', padding='same')(enc_AMOCindex_2) # (batch_size, 15, 8)\n",
    "    enc_AMOCindex_4 = Conv1D(filters=8, strides=stride_enc[3], kernel_size=kernel_size, activation='relu', padding='same')(enc_AMOCindex_3) # (batch_size, 5, 8)\n",
    "    \n",
    "#     print(enc_AMOCindex_1.shape)\n",
    "#     print(enc_AMOCindex_2.shape)\n",
    "#     print(enc_AMOCindex_3.shape)\n",
    "#     print(enc_AMOCindex_4.shape)\n",
    "    \n",
    "    enc_out = Concatenate(axis=2)([enc_AMOC_3] + [enc_AMOCindex_4]) # (batch_size, 5, 16)\n",
    "#     print(enc_out.shape)\n",
    "\n",
    "    z_mean = Dense(8)(enc_out) # (batch_size, 5, 8)\n",
    "    z_log_sigma = Dense(8)(enc_out) # (batch_size, 5, 8)\n",
    "    \n",
    "#     print(z_mean.shape)\n",
    "#     print(z_log_sigma.shape)\n",
    "\n",
    "    encoder = Model([inp_AMOC, inp_AMOCindex], [z_mean, z_log_sigma])\n",
    "\n",
    "    ### decoder ###\n",
    "\n",
    "    inp_z = Input(shape=z_mean.shape[1:]) # (batch_size, 5, 8)\n",
    "    \n",
    "#     print(inp_z.shape)\n",
    "\n",
    "    conv_1 = Conv1DTranspose(inp_z, filters=8, kernel_size=kernel_size, strides=stride_dec[0], padding='same', activation='relu') # (batch_size, 35, 8)\n",
    "    conv_2 = Conv1DTranspose(conv_1, filters=8, kernel_size=kernel_size, strides=stride_dec[1], padding='same', activation='relu') # (batch_size, 140, 8)\n",
    "    conv_3 = Conv1DTranspose(conv_2, filters=8, kernel_size=kernel_size, strides=stride_dec[2], padding='same', activation='relu') # (batch_size, 420, 8)\n",
    "    conv_4 = Conv1DTranspose(conv_3, filters=8, kernel_size=kernel_size, strides=stride_dec[3], padding='same', activation='linear') # (batch_size, 840, 8)\n",
    "    \n",
    "#     print(conv_1.shape)\n",
    "#     print(conv_2.shape)\n",
    "#     print(conv_3.shape)\n",
    "#     print(conv_4.shape)\n",
    "    \n",
    "    out = Dense(1)(conv_4) # (batch_size, 840, 1)\n",
    "#     print(out.shape)\n",
    "\n",
    "    decoder = Model([inp_z], [out])\n",
    "\n",
    "    ### encoder + decoder ###\n",
    "\n",
    "    z_mean, z_log_sigma = encoder([inp_AMOC, inp_AMOCindex])\n",
    "    z = Lambda(sampling)([z_mean, z_log_sigma])\n",
    "    pred = decoder([z])\n",
    "\n",
    "    vae = Model([inp_AMOC, inp_AMOCindex, AMOC_target], pred)\n",
    "    vae.add_loss(vae_loss(AMOC_target, pred, z_mean, z_log_sigma, tuning1=0, tuning2=0, tuning3=1.0, tuning4=tuning4_para))\n",
    "    vae.compile(loss=None, optimizer=Adam(learning_rate=1e-3))\n",
    "\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d05708-a62a-4b86-a141-af9108ba723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_model = get_model(AMOC_input_train_scaled.shape[1:], AMOCindex_input_train_scaled.shape[1:], target_train_scaled.shape[1:], tuning4_para = 1)\n",
    "# vae_model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e915730-c487-47c4-96b3-0600715876ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para: 1e-06\n"
     ]
    }
   ],
   "source": [
    "# Grid serach to find the best ratio between mse loss and KL-divergence in vae loss, the ratio is controlled by tuning parameter 4 in self-defined vae loss.\n",
    "grid_result = {}\n",
    "\n",
    "epoch_num = 200\n",
    "verbose = 0\n",
    "num_val_pred = 100\n",
    "tuning4_grid = [1e-6, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2]\n",
    "\n",
    "if AMOC_range == 140:\n",
    "    kernel_size = 60\n",
    "    stride_enc = (7,4,4,3)\n",
    "    stride_dec = (7,4,4,3)\n",
    "elif AMOC_range == 70:\n",
    "    kernel_size = 80\n",
    "    stride_enc = (7,4,2,3)\n",
    "    stride_dec = (7,4,3,2)\n",
    "else:\n",
    "    print('Need to define kernel size and stride size')\n",
    "\n",
    "nrows = math.ceil(len(tuning4_grid)/3)\n",
    "fig, axs = plt.subplots(nrows = nrows, ncols = 3, figsize = (20, 6*nrows))\n",
    "\n",
    "for i, para in enumerate(tuning4_grid):\n",
    "    print('para:', para)\n",
    "    # fit the model\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(seed)\n",
    "    es = [\n",
    "    EarlyStopping(patience=20, verbose=verbose, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=hyper_path+'beta_'+str(para)+'.hdf5', save_freq='epoch', save_best_only=True)]\n",
    "    vae_model = get_model(AMOC_input_train_scaled.shape[1:], AMOCindex_input_train_scaled.shape[1:], target_train_scaled.shape[1:], \n",
    "                          kernel_size = kernel_size, stride_enc = stride_enc, stride_dec = stride_dec, tuning4_para = para)\n",
    "    history = vae_model.fit([AMOC_input_train_scaled, AMOCindex_input_train_scaled, target_train_scaled], batch_size=128, epochs=epoch_num, validation_split=0.2, verbose=verbose, callbacks=es)\n",
    "    \n",
    "    # prediction on validation set\n",
    "    val_pred = np.zeros((num_val_pred, target_val_scaled.shape[0], target_val_scaled.shape[1], target_val_scaled.shape[2]))\n",
    "    for j in range(num_val_pred):\n",
    "        val_pred[j, :, :, :] = AMOC_scaler.inverse_transform(vae_model.predict([AMOC_input_val_scaled, AMOCindex_input_val_scaled, np.zeros(target_val_scaled.shape)], verbose = 0))\n",
    "#         if j%10 == 0:\n",
    "#             print(j)\n",
    "        \n",
    "    # record summary statistics\n",
    "    val_pred = np.squeeze(val_pred)\n",
    "    mean = np.mean(val_pred, axis = 0)\n",
    "    lower_q = np.quantile(val_pred, 0.025, axis = 0)\n",
    "    upper_q = np.quantile(val_pred, 0.975, axis = 0)\n",
    "#     std = np.std(val_pred, axis = 0)\n",
    "\n",
    "    grid_result[para] = [mean, lower_q, upper_q]\n",
    "    \n",
    "    # Visualize Model Training History\n",
    "    axs[i//3, i%3].plot(history.history['loss'])\n",
    "    axs[i//3, i%3].plot(history.history['val_loss'])\n",
    "    axs[i//3, i%3].set_title('Model loss for tuning4:' + str(para))\n",
    "    axs[i//3, i%3].set_ylabel('loss')\n",
    "    axs[i//3, i%3].set_xlabel('epoch')\n",
    "    axs[i//3, i%3].legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(hyper_path+'history.png', bbox_inches='tight')\n",
    "# np.save(outDATA_path+'grid_result.npy', grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527c534-f724-4837-af77-fee5e4b2341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid_result file\n",
    "# grid_result = np.load(outDATA_path+'grid_result.npy', allow_pickle=True)\n",
    "# grid_result = grid_result[()]\n",
    "\n",
    "# target = np.squeeze(AMOC_scaler.inverse_transform(target_val))\n",
    "target = np.squeeze(target_val)\n",
    "\n",
    "# np.save(outDATA_path+'val_target.npy', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a01df-f969-49c7-9b45-b45c0500da14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot mspe based on validation data\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "for key in grid_result:\n",
    "    val_pred_mean = grid_result[key][0]\n",
    "    mspe = np.mean(np.square(target - val_pred_mean))\n",
    "    plt.plot(math.log10(key), mspe, marker = 'o')\n",
    "#     plt.plot(math.log10(key), math.log10(mspe), marker = 'o')\n",
    "plt.title('Hyperparameter Tuning: MSPE')\n",
    "plt.xlabel(r'$\\log_{10} \\beta$')\n",
    "plt.ylabel('MSPE (Sv)')\n",
    "# plt.ylim((0, 2))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(hyper_path+'mspe.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1613aac-df99-48bb-a73a-9abfe867afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot empirical coverage based on validation data set\n",
    "\n",
    "labels = []\n",
    "emp_coverage = []\n",
    "mae = []\n",
    "\n",
    "for key in grid_result:\n",
    "    # calculate empirical probability over validation data set\n",
    "    mean = grid_result[key][0]\n",
    "#     std = grid_result[key][1]\n",
    "#     ci = 1.96 * std\n",
    "#     lower = mean - ci\n",
    "#     upper = mean + ci\n",
    "    lower = grid_result[key][1]\n",
    "    upper = grid_result[key][2]\n",
    "    count = np.sum((target >= lower) & (target <= upper), axis = 1)\n",
    "    emp_prob = count/target_val.shape[1]\n",
    "    \n",
    "    # calculate mae over validation data set\n",
    "    val_bias = np.mean(np.absolute(target - mean), axis=1)\n",
    "    \n",
    "    labels.append(math.log10(key))\n",
    "    emp_coverage.append(emp_prob)\n",
    "    mae.append(val_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519078ef-cf18-43ba-ac64-a864f378d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot empirical coverage based on validation data set\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(emp_coverage,\n",
    "            positions=list(range(len(labels))),\n",
    "            labels=labels)\n",
    "plt.axhline(y=0.95, color='red', linestyle='--', lw=1)\n",
    "plt.title('Hyperparameter Tuning: Boxplot of Empirical Coverage')\n",
    "plt.xlabel(r'$\\log_{10} \\beta$')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(hyper_path+'box_emp_coverage.png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0212f-c590-4f55-ac34-0b2d70e9a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mae based on validation data set\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(mae,\n",
    "            positions=list(range(len(labels))),\n",
    "            labels=labels)\n",
    "plt.title('Hyperparameter Tuning: Boxplot of MAE')\n",
    "plt.xlabel(r'$\\log_{10} \\beta$')\n",
    "plt.ylabel('MAE (Sv)')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(hyper_path+'box_mae.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecafab0-7256-47ad-a89e-b258c63c2685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_para = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd7cac2-ed52-4aac-b611-547638994181",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path to save model output: folder 'model_output' will not be shown on git \n",
    "# repo as the file is large, no need to git it.\n",
    "file = outDATA_path+'beta_' + str(best_para) + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652324a8-8994-469b-9ad9-c509ff220a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with best hyper parameter\n",
    "\n",
    "# combine training and validation data\n",
    "AMOC_input_train_scaled = np.concatenate((AMOC_input_train_scaled, AMOC_input_val_scaled), axis = 0)\n",
    "AMOCindex_input_train_scaled = np.concatenate((AMOCindex_input_train_scaled, AMOCindex_input_val_scaled), axis = 0)\n",
    "target_train_scaled = np.concatenate((target_train_scaled, target_val_scaled), axis = 0)\n",
    "\n",
    "# train model\n",
    "epoch_num = 200\n",
    "verbose = 0\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(seed)\n",
    "es = [\n",
    "EarlyStopping(patience=20, verbose=verbose, min_delta=0.001, monitor='val_loss', mode='auto', restore_best_weights=True),\n",
    "ModelCheckpoint(filepath=hyper_path+'best_model_beta_'+str(best_para)+'.hdf5', save_freq='epoch', save_best_only=True)]\n",
    "vae = get_model(AMOC_input_train_scaled.shape[1:], AMOCindex_input_train_scaled.shape[1:], target_train_scaled.shape[1:], \n",
    "                kernel_size = kernel_size, stride_enc = stride_enc, stride_dec = stride_dec, tuning4_para = para)\n",
    "history = vae.fit([AMOC_input_train_scaled, AMOCindex_input_train_scaled, target_train_scaled], batch_size=128, epochs=epoch_num, validation_split=0.2, verbose=verbose, callbacks=es)\n",
    "\n",
    "# Visualize Model Training History\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss for beta:' + str(best_para))\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "np.save(file + 'history.npy', history.history)\n",
    "fig.savefig(hyper_path+'best_model_beta_'+str(best_para)+'_history.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa38b4-93be-4206-bff5-3bb2e4bd8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: prediction for test data set 'test_pred' need 421. GiB memory, \n",
    "# ensure have enough space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf4f89-3823-4fe4-b64f-9fcdec8a13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = load_model(hyper_path+'best_model_beta_'+str(best_para)+'.hdf5')\n",
    "\n",
    "# Pred testing data set, prediction results should be in original scale\n",
    "test_pred = np.zeros((1000, target_test_scaled.shape[0], target_test_scaled.shape[1], target_test_scaled.shape[2]))\n",
    "\n",
    "tf.random.set_seed(seed+1)\n",
    "for i in range(1000):\n",
    "    test_pred[i, :, :, :] = AMOC_scaler.inverse_transform(vae.predict([AMOC_input_test_scaled, AMOCindex_input_test_scaled, np.zeros(target_test_scaled.shape)], verbose = 0))\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d174e-4fff-4b04-9479-878afa0dfdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ATTENTION: prediction for test data set 'test_pred' need 421. GiB memory, \n",
    "# # ensure have enough space.\n",
    "\n",
    "# np.save(file + 'test_pred.npy', test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd6898c-7a52-481d-b52a-867dca507f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some case in testing data set\n",
    "\n",
    "i = 1000\n",
    "\n",
    "test_pred_1000 = test_pred[:, i, :, :]\n",
    "AMOC_input_test_0 = AMOC_input_test[i, :, :]\n",
    "AMOCindex_input_test_0 = AMOCindex_input_test[i, :, :]\n",
    "target_test_0 = target_test[i, :, :]\n",
    "\n",
    "assert debug(AMOC_input_test, AMOC_input_test_scaled, AMOC_scaler)\n",
    "assert debug(AMOCindex_input_test, AMOCindex_input_test_scaled, AMOCindex_scaler)\n",
    "assert debug(target_test, target_test_scaled, AMOC_scaler)\n",
    "\n",
    "test_pred_1000 = np.squeeze(test_pred_1000)\n",
    "AMOC_input_test_0 = np.squeeze(AMOC_input_test_0)\n",
    "AMOCindex_input_test_0 = np.squeeze(AMOCindex_input_test_0)\n",
    "target_test_0 = np.squeeze(target_test_0)\n",
    "\n",
    "### confidence interval ###\n",
    "test_pred_1000 = np.squeeze(test_pred_1000)\n",
    "mean = np.mean(test_pred_1000, axis=0)\n",
    "lower = np.quantile(test_pred_1000, 0.025, axis = 0)\n",
    "upper = np.quantile(test_pred_1000, 0.975, axis = 0)\n",
    "# std = np.std(test_pred_1000, axis=0)\n",
    "# ci = 1.96 * std\n",
    "x = np.linspace(1, test_pred_1000.shape[1], test_pred_1000.shape[1])\n",
    "\n",
    "mask = np.array(~AMOC_Obs['Obs'].isna())\n",
    "\n",
    "foo = plt.figure(figsize=(15, 5))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.tight_layout(pad = 2)\n",
    "for j in range(6):\n",
    "    plt.plot(x[mask][j], AMOC_input_test_0[j], c='red', marker='x')\n",
    "plt.plot(x[mask][6:], AMOC_input_test_0[6:], c='red', label='Observations')\n",
    "plt.plot(target_test_0, c='blue', label='True mean trend')\n",
    "plt.plot(mean, c='orange', label='Estimated mean trend')\n",
    "plt.fill_between(x, lower, upper, color='navy', alpha=.2)\n",
    "plt.ylabel(r'AMOC [Strength (Sv)]')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(AMOCindex_input_test_0, c='lightgray', label='AMOC index')\n",
    "plt.ylabel('Temperature ($^\\circ$C)')\n",
    "plt.legend()\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cebc872-2481-426a-bd42-31722127fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save some representative testing data case\n",
    "for i in [0, 1000, 4000, 8000, 10000]:\n",
    "    np.save(file + 'test_pred_'+str(i)+'.npy', test_pred[:, i, :, :])\n",
    "    np.save(file + 'AMOC_input_test_'+str(i)+'.npy', AMOC_input_test[i, :, :])\n",
    "    np.save(file + 'AMOCindex_input_test_'+str(i)+'.npy', AMOCindex_input_test[i, :, :])\n",
    "    np.save(file + 'target_test_'+str(i)+'.npy', target_test[i, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c76ec-ec06-4367-bfd5-177716a7bea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pred Observation data, prediction results should be in original scale ###\n",
    "AMOC_Obs = np.array(AMOC_Obs.loc[~AMOC_Obs['Obs'].isna(), 'Obs']).reshape((1, -1, 1))\n",
    "AMOC_Obs = AMOC_Obs - AMOC_Obs.mean()\n",
    "AMOC_Obs_scaled = AMOC_scaler.transform(AMOC_Obs)\n",
    "\n",
    "AMOCindex_Obs = np.array(AMOCindex_Obs[['Obs']]).reshape((1, -1, 1))\n",
    "AMOCindex_Obs = AMOCindex_Obs - AMOCindex_Obs.mean()\n",
    "AMOCindex_Obs_scaled = AMOCindex_scaler.transform(AMOCindex_Obs)\n",
    "\n",
    "# debugger to check if AMOC and AMOC index observation data is in 0-1 range\n",
    "assert np.min(AMOC_Obs_scaled) > 0\n",
    "assert np.max(AMOC_Obs_scaled) < 1\n",
    "assert np.min(AMOCindex_Obs_scaled) > 0\n",
    "assert np.max(AMOCindex_Obs_scaled) < 1\n",
    "\n",
    "Obs_pred = np.zeros((1000, target_test_scaled.shape[1], target_test_scaled.shape[2]))\n",
    "\n",
    "tf.random.set_seed(seed+2)\n",
    "for i in range(1000):\n",
    "    Obs_pred_0 = AMOC_scaler.inverse_transform(vae.predict([AMOC_Obs_scaled, AMOCindex_Obs_scaled, np.zeros((1, target_test_scaled.shape[1], target_test_scaled.shape[2]))], verbose = 0))\n",
    "    Obs_pred[i, :, :] = np.squeeze(Obs_pred_0, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44844e9d-6a3d-4be6-8731-23cd83303ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(file + 'Obs_pred.npy', Obs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b70020-44da-495b-a2cb-1ca83303aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get emp_prob: for each testing data set, find confidence interval over 1,000 trails prediction generated from vae, check if target value is in constructed confidence interval. \n",
    "# The ideal empircal probability should be 0.95 as we are constructing 95% CI.\n",
    "# target = np.squeeze(AMOC_scaler.inverse_transform(target_test)) # shape: (28,000, 840)\n",
    "target = np.squeeze(target_test) \n",
    "assert debug(target_test, target_test_scaled, AMOC_scaler)\n",
    "test_pred_1000 = np.squeeze(test_pred)\n",
    "\n",
    "# emp_prob\n",
    "mean = np.mean(test_pred_1000, axis=0)\n",
    "lower = np.quantile(test_pred_1000, 0.025, axis = 0)\n",
    "upper = np.quantile(test_pred_1000, 0.975, axis = 0)\n",
    "# std = np.std(test_pred_1000, axis=0)\n",
    "# ci = 1.96 * std\n",
    "# lower = mean - ci\n",
    "# upper = mean + ci\n",
    "count = np.sum((target >= lower) & (target <= upper), axis = 1)\n",
    "emp_prob = count/target_test.shape[1]\n",
    "\n",
    "# bias\n",
    "test_bias = target - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0403b4fe-5e47-4522-839b-86d71da24897",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file + 'emp_prob.npy', emp_prob)\n",
    "np.save(file + 'test_bias.npy', test_bias)\n",
    "np.save(file + 'test_pred_mean.npy', mean)\n",
    "np.save(file + 'test_pred_std.npy', std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Conda 2019.10) [python/3.7-2019.10]",
   "language": "python",
   "name": "python37_201910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
